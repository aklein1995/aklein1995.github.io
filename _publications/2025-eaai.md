---
title: "Evaluating Reinforcement Learning-Based Neural Controllers for Quadcopter Navigation in Windy Conditions"
collection: publications
permalink: #
excerpt: #'This paper is about the number 1. The number 2 is left for future work.'
date: 2025-08-20
venue: 'Engineering Applications of Artificial Intelligence'
paperurl: 'https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence'
citation: #'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
authors: Alain Andres*, Aritz D Martinez, Sümer Tunçay, Ignacio Carlucho
---

**Abstract**: Accurate quadcopter navigation under windy conditions remains challenging for traditional control methods, especially in the presence of unpredictable wind gusts and strict navigational constraints. This paper evaluates Deep Reinforcement Learning (DRL) based controllers under such conditions, analysing the impact of wind domain randomisation, multi-goal training, enhanced state representations with explicit wind information, and the use of temporal data to capture affecting dynamics over time.

Experiments in the AirSim simulator across four trajectories—evaluated under both no-wind and windy conditions— demonstrate that DRL-based controllers outperform classical methods, particularly under stochastic wind disturbances. Moreover, we show that training a DRL agent with domain randomization improves robustness against wind but reduces efficiency in no-wind scenarios. However, incorporating wind information into the agent’s state space enhances robustness without sacrificing performance in wind-free settings. Furthermore, training with stricter waypoint constraints emerges as the most effective strategy, leading to precise trajectories and improved generalization to wind disturbances.To further interpret the learned policies, we apply Shapley Additive explanations analysis, revealing how different training configurations influence the agent's feature importance. 
These findings underscore the potential of DRL-based neural controllers for resilient autonomous aerial systems, highlighting the importance of structured training strategies, informed state representations, and explainability for real-world deployment.